{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304867a6",
   "metadata": {},
   "source": [
    "# ðŸ“Š 04_clean_BNPL_intention_to_use.ipynb\n",
    "\n",
    "## ðŸŽ¯ Purpose\n",
    "\n",
    "This notebook prepares the dataset `BNPL_intention_to_use.xlsx` \n",
    "from Indian Institute of Management Lucknow.This dataset contains structured survey responses from 226 young shoppers in India to measure their intention to adopt Buy Now, Pay Later (BNPL) services. The data includes responses to Likert-scale items representing key behavioral constructs such as Financial Literacy, Performance Expectancy, Effort Expectancy, Perceived Usefulness, Attitude, and Intention to Use\n",
    "\n",
    "## Relevance to Our Research\n",
    "Limitations of this Source\n",
    "Our project investigates how demographic and financial \n",
    "behavior features influence default risk across BNPL and \n",
    "traditional loans. This dataset is **Not usable for modeling** \n",
    "because:\n",
    "\n",
    "- It has **no outcome labels** (like default vs. non-default).\n",
    "- It has **no demographic features** (like age,gender,income,etc.).\n",
    "- It needs more **Financial Behavior features** (such as credit score, existing debts, repayment history)\n",
    "- The dataset is **cross-sectional**, not longitudinal, so it captures intentions at a single time point, not actual adoption behavior over time.\n",
    "- Coded headers (e.g., FL1, PE3) require a **codebook** or original questionnaire to interpret meaningfully.\n",
    "\n",
    "We can use this dataset:\n",
    "\n",
    "- In **data exploration of attitudes and intentions**, not for modeling default risk.\n",
    "\n",
    "If we have access to more data or can collect follow-up information, we can make this dataset much more actionable for our research question.\n",
    "\n",
    "## Output\n",
    "\n",
    "Cleaned version saved in:\n",
    "- `../1_datasets/reference/BNPL_intention_to_use_cleaned.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a284afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Lenovo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install openpyxl\n",
    "# Import pandas for data handling\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc17a2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL1</th>\n",
       "      <th>FL2</th>\n",
       "      <th>FL3</th>\n",
       "      <th>PE1</th>\n",
       "      <th>PE2</th>\n",
       "      <th>PE3</th>\n",
       "      <th>EE1</th>\n",
       "      <th>EE2</th>\n",
       "      <th>EE3</th>\n",
       "      <th>EE4</th>\n",
       "      <th>...</th>\n",
       "      <th>PU1</th>\n",
       "      <th>PU2</th>\n",
       "      <th>PU3</th>\n",
       "      <th>IA1</th>\n",
       "      <th>IA2</th>\n",
       "      <th>IA3</th>\n",
       "      <th>AT1</th>\n",
       "      <th>AT2</th>\n",
       "      <th>AT3</th>\n",
       "      <th>AT4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FL1  FL2  FL3  PE1  PE2  PE3  EE1  EE2  EE3  EE4  ...  PU1  PU2  PU3  IA1  \\\n",
       "0    6    4    4    5    5    5    6    5    5    5  ...    5    5    3    4   \n",
       "1    5    5    5    4    5    5    2    3    4    4  ...    6    6    6    2   \n",
       "2    6    6    6    5    3    6    6    6    6    6  ...    3    6    2    4   \n",
       "3    3    5    5    2    5    2    2    3    5    5  ...    3    5    5    2   \n",
       "4    5    5    5    6    4    6    6    4    4    6  ...    5    5    6    3   \n",
       "\n",
       "   IA2  IA3  AT1  AT2  AT3  AT4  \n",
       "0    4    4    6    6    6    6  \n",
       "1    2    2    5    5    4    5  \n",
       "2    3    3    6    7    6    5  \n",
       "3    2    2    6    6    3    5  \n",
       "4    3    4    4    3    2    2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"../1_datasets/raw_data/BNPL Intention to use.xlsx\")\n",
    "\n",
    "# Preview the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52cb58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FL1', 'FL2', 'FL3', 'PE1', 'PE2', 'PE3', 'EE1', 'EE2', 'EE3', 'EE4', 'PA1', 'PA2', 'PA3', 'PC1', 'PC2', 'PC3', 'PRE1', 'PRE3', 'PU1', 'PU2', 'PU3', 'IA1', 'IA2', 'IA3', 'AT1', 'AT2', 'AT3', 'AT4']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1288290",
   "metadata": {},
   "source": [
    "## ðŸ”Ž Variable Description\n",
    "\n",
    "| Acronym               | Description                          |\n",
    "|-----------------------|--------------------------------------|\n",
    "| FL                    | Financial Literacy                   |\n",
    "| PE                    | Performance Expectancy               |\n",
    "| EE                    | Effort Expectancy                    |\n",
    "| PA                    | Perceived Advantage                  |\n",
    "| PC                    | Perceived Compatibility              |\n",
    "| PRE                   | Perceived Risk                       |\n",
    "| PU                    | Perceived Usefulness                 |\n",
    "| IA                    | Intention to Adopt/Use               |\n",
    "| AT                    | Attitude Toward (BNPL, technology, etc.)                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910a7767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing data\n",
    "missing = df[df.isnull().any(axis=1)]\n",
    "print(\"Number of rows with missing values:\", len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ffa456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      " FL1     int64\n",
      "FL2     int64\n",
      "FL3     int64\n",
      "PE1     int64\n",
      "PE2     int64\n",
      "PE3     int64\n",
      "EE1     int64\n",
      "EE2     int64\n",
      "EE3     int64\n",
      "EE4     int64\n",
      "PA1     int64\n",
      "PA2     int64\n",
      "PA3     int64\n",
      "PC1     int64\n",
      "PC2     int64\n",
      "PC3     int64\n",
      "PRE1    int64\n",
      "PRE3    int64\n",
      "PU1     int64\n",
      "PU2     int64\n",
      "PU3     int64\n",
      "IA1     int64\n",
      "IA2     int64\n",
      "IA3     int64\n",
      "AT1     int64\n",
      "AT2     int64\n",
      "AT3     int64\n",
      "AT4     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for data types\n",
    "data_types = df.dtypes\n",
    "print(\"Data types of each column:\\n\", data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a41015",
   "metadata": {},
   "source": [
    "## Save Cleaned Dataset\n",
    "\n",
    "Although this dataset is not used for modeling, we preserve it \n",
    "for potential exploratory or historical comparison.\n",
    "\n",
    "We store it in the `/1_datasets/reference/` folder to distinguish \n",
    "it from modeling datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932f362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved cleaned reference dataset.\n"
     ]
    }
   ],
   "source": [
    "# Save to a reference subfolder\n",
    "df.to_csv(\"../1_datasets/reference/BNPL_intention_to_use_cleaned.csv\", index=False)\n",
    "\n",
    "print(\" Saved cleaned reference dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
